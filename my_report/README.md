# Lesson: Advanced Interaction Technologies & Applications

### First and Last Name: Πιπεράκη Στυλιανή Ραφαέλλα 🌻
### University Registration Number: dpsd19109
### GitHub Personal Profile: https://github.com/StellaPiperaki
### Advanced Interaction Tecnologies & Applications Github Personal Repository:
### https://github.com/StellaPiperaki/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment

# Introduction

# Summary


# 1st Deliverable
#### 1.Video Capture: 
Για το πρώτο βήμα χρειάστηκε να κάνω install την βιβλιοθήκη video library for proseccing 3,ώστε να μπορέσει να ανοίξει η κάμερα και να διαβαστούν οι εντολές από το example.

<img  src="https://user-images.githubusercontent.com/101418268/199677535-c1f18788-1811-4060-8dc0-924266eeda67.png" width="420"/>

#### 2.Recorded video:
Για το δέυτερο βήμα διάλεξα ένα βιντεάκι λίγων δευτερολέπτων από ένα ηλιοβασίλεμα της Μυκόνου το καλοκαίρι και μίκρηνα το μέγεθος του καθώς ήταν αρκετά μεγάλο αρχείο. 
Στη συνέχεια αποθήκευσα το βίντεο μέσα στον φάκελο data που ήταν μέσα στο exercise 16-2. Τέλος έβαλα το αρχείο με το βιντεό μου, (sunset.mp4) και έκανα καποιες τροποποιήσεις στον κώδικα.

<img  src="https://user-images.githubusercontent.com/101418268/199678613-621ad2ec-9b51-440c-a132-fe6778a350b9.png" width="420"/>

#### 3.QR Code: 
Για το τρίτο βήμα χρειάστηκε να κατεβάσω μια βιβλιοθήκη QR code και έφτιαξα το δικό μου QR και πρόσθεσα το URL του λογαριασμού μου στο Github.

<img  src="https://user-images.githubusercontent.com/101418268/199680113-de434dc5-b5ff-4b89-be33-81f23e24d98f.png" width="420"/> <img  src="https://user-images.githubusercontent.com/101418268/199680159-8f379e41-5255-430d-a239-d6acecf87172.png" width="420"/>

#### 4.QR Code - Camera Read:
Για το τέταρτο βήμα χρειάστηκε να κάνω κάποιες αλλαγές στον κώδικα και άλλαξα το loadimage , τοποθετώντας την εικόνα μέσα στον φάκελο data για ν αμπορέσει να την διαβάσει το πρόγραμμα.

<img  src="https://user-images.githubusercontent.com/101418268/199680222-2021f4ab-fcf6-4633-8695-c5c9e5c3919d.png" width="420"/> <img  src="https://user-images.githubusercontent.com/101418268/199680272-84a7e94d-c7b4-48ee-979e-6ab4e842f3a1.png" width="420"/>

#### 5.Augmented Reality: 
Για το πέμπτο και τελευταίο βήμα του πρώτου παραδοτέου επίσης έκανα κάποιες αλλαγές στον κώδικα και δημιούργησα ένα φάκελο data και πρόσθεσα την εικόνα που θέλω να προβάλλεται με όνομα cat.png, ανέβασα τον φάκελο data ώστε να διαβαστεί η εικόνα και όταν διαβάζει το hiro η κάμερα να εμφανίζεται η εικόνα της γάτας μου.

<img  src="https://user-images.githubusercontent.com/101418268/199680439-22036598-bd9e-4136-a8df-c74368b16aa5.png" width="420"/> <img  src="https://user-images.githubusercontent.com/101418268/199680472-bc8f6579-7aaf-4eac-86c3-f8272963c103.png" width="420"/>
<img  src="https://user-images.githubusercontent.com/101418268/199838572-daff9c18-13fd-4fca-a58b-4e397d03beb1.png" width="420"/>

# 2nd Deliverable

#### 1.Backround Removal:
Στο πρώτο βήμα βασίστηκα στην άσκηση 16.6 και σκοπός είναι η αφαίρεση του background και να προσθέσω ένα βίντεο (stars.mp4) και σε ένα δεύτερο αρχείο να προσθέσω για το background μια εικόνα (milos.mp4). Το αποτέλεσμα με την εικόνα για το background είναι στην παρακάτω φωτογραφία.


https://user-images.githubusercontent.com/101418268/207150732-b6b5d703-c062-4401-b9ca-9cfd45884d5a.mov

<img  src="https://user-images.githubusercontent.com/101418268/207149956-caa15f0c-2845-4741-84b5-a15c2aae41fd.png" width="420"/> <img  src="https://user-images.githubusercontent.com/101418268/206520419-66cc35bb-230e-406d-af9d-71a20520eef5.png" width="420"/>

#### 2.Motion Detection:
Για το δεύτερο βήμα βασίστηκα στο παράδειγμα 16.7, αλλάζοντας τη σφαίρα και έφτιαξα ένα ορθογώνιο και άλλαξα και το χρώμα και το έκανα πορτοκαλί. Στο παρακάτω βίντεο και στις φωτογραφίες φαίνεται η κίνηση του ορθογωνίου όταν κουνάω το χεέρι μου , η κάμερα αντιλμβάνεται την κίνηση του χεριού και το ορθογώνιο την ακολουθεί.

 https://user-images.githubusercontent.com/101418268/206520905-0f03cc75-5542-4656-ab9a-268b12a6fd8b.mov 
 
<img  src="https://user-images.githubusercontent.com/101418268/206526079-03edad3d-2ae4-44db-ab49-d2b21cc1966d.PNG" width="260"/> <img  src="https://user-images.githubusercontent.com/101418268/206526314-68c16ac9-d643-440e-a5cf-25393ab7847e.jpg" width="320"/>

#### 3.Backround Substraction:
Για το τρίτο βήμα χρειάστηκε να εγκαταστήσω την βιβλιοθήκη OpenCV, έπειτα πήρα βοήθεια  στο παράδειγμα Background Substraction και  διέγραψα το υπάρχον βίντεο ώστε η κάμερα να αντιλαμβάνεται την κίνηση του ατόμου και το περίγραμμά του. Τα αποτελέσματα φαίνονται στο παρακάτω βίντεο.

Ποια είναι τα πλεονεκτήματα και μειονεκτήματα της έτοιμης βιβλιοθήκης έναντι του κώδικα από το πρώτο ερώτημα;Με την OpenCV:
Τα πλεονεκτήματα της έτοιμης βιβλιοθήκης με την OpenCV είναι ότι, ο κώδικας είναι ήδη διαμορφωμένος , το openCV  αναλύει και εντοπίζει καλύτερα ένα αντικείμενο της εικόνας ευκολότερα ακόμα και αν ο άνθρωπος είτε το αντικείμενο κινείται, ειναι καταλληλη για εφαρμογες με χρηση καμερας σε πραγματικο χρονο . Τα αρνητικά της έτοιμης βιβλιοθήκης είναι ότι θα πρέπει να την εγκαταστήσω και αυτό μπορεί να πάρει αρκετό χρόνο.
  

https://user-images.githubusercontent.com/101418268/206521318-e9ffa2c5-6ea2-4aa0-9a76-e3700d9ab418.mov

<img  src="https://user-images.githubusercontent.com/101418268/206526392-75feb810-2544-42df-b300-3820e2f5791c.jpg" width="200"/> <img  src="https://user-images.githubusercontent.com/101418268/206526592-12704105-51d9-460d-bf9f-2761ac2d6e88.jpg" width="220"/>

#### 4.Object Tracking:
Για το τέταρτο και τελευταίο βήμα του 2ου παραδοτέου βασίστηκα στο παράδειγμα "snake" και άλλαξα το χρώμα που θα φαίνονται τα κυκλάκια όταν ακολουθεί η κάμερα ένα άσπρο αντικείμενο. Κάθε φορά που εντοπίζει ένα άσπρο αντικείμενο δημιουργείται μία ουρά σαν φιδάκι και ακολουθεί το ένα κυκλάκι το άλλο.

Σε σχέση με το παραδοσιακό ποντίκι ποια είναι τα πλεονεκτήματα και ποια τα μειονεκτήματα αυτής της τεχνικής ελέγχου ενός ή περισσότερων σημείων σε μια οθόνη;:
Τα πλεονεκτήματα της τεχνικής ελέγχου είναι ότι μπορεί να γίνει από απόσταση, χρειάζεται να υπάρχει μονο κάμερα και γίνεται πιο εύκολη η πρόσβαση.Τα μειονεκτήματα είναι πως κολλάει αρκετά με αποτέλεσμα να δυσκολεύει τη διαδικασία και πως δεν είναι πάντοτε αποτελεσματικό.

https://user-images.githubusercontent.com/101418268/206542383-f8e1d349-8ee0-46ec-aeb2-872cfb3978b8.mp4

<img  src="https://user-images.githubusercontent.com/101418268/206536068-977181ce-70ff-4c4b-99fa-1f2008657491.jpg" width="320"/> <img  src="https://user-images.githubusercontent.com/101418268/206536123-5198f390-210b-4c05-beb8-9b31f8068a72.jpg" width="320"/>
<img  src="https://user-images.githubusercontent.com/101418268/206536205-f4fd7950-cfb4-4b72-8dea-105aea9ec34d.jpg" width="320"/>

# 3rd Deliverable 
Για το τριτο παραδοτέο ;έκανα εγκατάσταση της εφαρμογής reacTIVision vision engine, της βιβλιοθήκης reacTIVision στο Processing και της εφαρμογής TUIO Simulator.
Έπειτα πρόσθεσα κάποιες "if" όπου που αντιστοιχούν σε όλες τις επιλογές και για την κάθε επιλογή γίνετε οι αλλαγές, μετασχηματισμοί.
Στις εικόνες και στα βίντεο παρακάτω φαινονται οι αλλαγές και οι μετασχηματισμοί

Με το σχήμα 0 εισάγω και αλλάζω τη θέση της εικόνας:
![Screenshot (4)](https://user-images.githubusercontent.com/101418268/212463388-cff97df4-89eb-4546-990e-19759b73f9cd.png)
![Screenshot (5)](https://user-images.githubusercontent.com/101418268/212463420-efae44a5-aafb-416d-9c46-41ac188f0046.png)
Με το σχήμα 1 αλλάζω το χρώμα σε πράσινο και ρυθμίζω την πυκνότητα του χρώματος:
![Screenshot (6)](https://user-images.githubusercontent.com/101418268/212463432-128679c8-548b-4ddb-b74f-7e0b28566f4c.png)
Με το σχήμα 2 περιστρέφω την εικόνα:
![Screenshot (7)](https://user-images.githubusercontent.com/101418268/212463437-5624803a-dfdd-4156-a774-ea3a3f82d787.png)
Με το σχήμα 3 κάνω zoom in zoom out την εικόνα:
![Screenshot (8)](https://user-images.githubusercontent.com/101418268/212463443-f1a87427-0fd9-45be-975c-25caf78ff76b.png)

![Screenshot (9)](https://user-images.githubusercontent.com/101418268/212463463-be9a73a4-784e-4e2f-a450-eb99279021c0.png)
Με το 4 σχημα αλλαζω το opacity:
![Screenshot (10)](https://user-images.githubusercontent.com/101418268/212463477-e12ab662-b568-4324-a5fc-a6100b9b24e6.png)

https://user-images.githubusercontent.com/101418268/212463964-e9e1ce1f-f7cf-4d87-8bf5-b9afeb8646ac.mov
https://user-images.githubusercontent.com/101418268/212464085-89ef5b2b-0dd7-4343-bd0c-b8015cc65066.mov
https://user-images.githubusercontent.com/101418268/212463985-64d86131-578a-4ecd-a70d-6204ac222e47.mov
https://user-images.githubusercontent.com/101418268/212464007-2d4a07b2-1c74-4d60-9dc5-3f575c41f441.mov
https://user-images.githubusercontent.com/101418268/212464011-333a634f-85be-4497-9aed-5baab69edc02.mov

# Bonus 


# Conclusions


# Sources
#### Για το 1ο παραδοτέο:
https://processing.org/tutorials/video#live-video
βιβλίο του Daniel Shiffman από το eclass
https://www.youtube.com/watch?v=nJWV7X7df9w
https://www.youtube.com/watch?v=lJoUhLyI1TM
https://processing.org/examples/embeddedlinks.html
#### Για το 2ο παραδοτέο:
https://learnopencv.com/the-complete-guide-to-object-tracking-in-computer-vision
https://processing.org
βιβλίο του Daniel Shiffman από το eclass
proseccing examples
